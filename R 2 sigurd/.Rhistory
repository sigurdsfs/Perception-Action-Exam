as.data.frame(m$tn_trajectories)
mt_plot(
m,
use = 'tn_trajectories',
color = 'trial_type'
)
mt_plot(
m,
x = 'timestamps',
y = 'xpos',
use = 'tn_trajectories',
color = 'trial_type'
)
#Final prep of data.
#Make the end and start point together.
m <- mt_align(
m,
use = "tn_trajectories",
save_as = "tn_align_trajec",
dimensions = c("xpos", "ypos"),
coordinates = "norm",
align_start = TRUE ,
align_end = TRUE,
align_side = "no",
verbose = FALSE
)
#Standardize trajectories following Z-distirbution
m <- mt_scale_trajectories(
m,
use = "tn_align_trajec",
save_as = "final_trajec",
c("xpos", "ypos"),
center = TRUE,
scale = TRUE,
within_trajectory = FALSE,
prefix = "z_",
transform = NULL
)
mt_plot_aggregate(
m,
use = 'tn_align_trajec',
color = 'trial_type'
) +
labs(
title = 'Aggregated time-normalized mouse trajectories')
#Measures calculated using tn (time normalized and space normalized)
m <- mt_measures(
m,
use = 'tn_trajectories')
#### FIX ### LOOK AT WITH NIELS.
#derivs calculated using tn (time normalized) (we did not space normalize but maybe that is ok)
m <- mt_derivatives(
m,
save_as = 'deriv',
use = "tn_trajectories",
dimensions = c("xpos", "ypos"),
timestamps = "timestamps",
prefix = "",
absolute = FALSE,
return_delta_time = FALSE,
verbose = FALSE
)
derivs <- mt_export_wide(m$deriv)
toMatch <- c("acc", "vel", "time", "dist")
derivs <- derivs[, grepl(paste(toMatch, collapse = "|"), names(derivs))]
trajec <- mt_export_wide(m$final_trajec)
toMatch2 <- c("z_")
trajecs_ok <- trajec[, grepl(paste(toMatch2, collapse = "|"), names(trajec))]
spivey_df_data <- cbind(trajecs_ok, derivs, m$data)
# USe this data for Using MAD, MD (Maximum Deviation), AUC (Area under the curve for optimal straight line).
m$measures
roc()
write_csv(spivey_df_data, "spivey_norm_derv_data.csv")
#ORDER: X, Y, ACC, dist, time, vel
#DESIRED: X, y, V ,A
oldnames <- c(colnames(spivey_df_data)[1:202],colnames(spivey_df_data)[506:606], colnames(spivey_df_data)[203:303])
#Time , X , Y , Steps, dist, vel , acc
new_names <- c(#paste0("t",sprintf('%0.3d', 1:101)),
paste0("x",sprintf('%0.3d', 1:101)),
paste0("y",sprintf('%0.3d', 1:101)),
#paste0("s",sprintf('%0.3d', 1:101)),
#paste0("d",sprintf('%0.3d', 1:101)),
paste0("v",sprintf('%0.3d', 1:101)),
paste0("a",sprintf('%0.3d', 1:101)))
pacman::p_load(data.table)
setnames(spivey_df_data, old = oldnames, new = new_names)
setnames(spivey_df_data, old = c("subject_nr", "live_row", "trial_type", "response"), new = c("Subject", "Item.number", "Polarity", "Response"))
#Turn numeric
x <- paste0('x', sprintf("%03d", c(1:101)))
y <- paste0('y', sprintf("%03d", c(1:101)))
a <- paste0('a', sprintf("%03d", c(1:101)))
v <- paste0('v', sprintf("%03d", c(1:101)))
# <- paste0('t', sprintf("%03d", c(1:101)))
spivey_df_data[y] <- sapply(spivey_df_data[y],as.numeric)
spivey_df_data[x] <- sapply(spivey_df_data[x],as.numeric)
spivey_df_data[v] <- sapply(spivey_df_data[v],as.numeric)
spivey_df_data[a] <- sapply(spivey_df_data[a],as.numeric)
#normalized_positions_tr_spivey[t] <- sapply(normalized_positions_tr_spivey[t],as.numeric)
#Select only those with X,Y,V,A
all_data_columns_spivey <- names(dplyr::select(spivey_df_data,
starts_with("x"),
starts_with("y"),
starts_with("v"),
starts_with("a")))
normalized_positions.new.spivey <- spivey_df_data %>%
dplyr::select(Subject, Item.number, Polarity, Response, one_of(all_data_columns_spivey))
#write_csv(normalized_positions.new.spivey, "spivey_data_normalized_newnames_subset.csv")
#Find Constant Col's
constant_columns_ctl <- normalized_positions.new.spivey %>%
filter(Polarity == "control") %>%
dplyr::select(starts_with("x"), starts_with("y"), starts_with('v'), starts_with('a')) %>%
find_constant
constant_columns_nctl <- normalized_positions.new.spivey %>%
filter(Polarity == "cohort") %>%
dplyr::select(starts_with("x"), starts_with("y"), starts_with('v'),starts_with('a')) %>%
find_constant
constant_columns <- c(constant_columns_ctl, constant_columns_nctl)
#Remove constant col
normalized_positions_tr_spivey <- dplyr::select(normalized_positions.new.spivey,
-one_of(constant_columns))
#Another way to remove constant col's
normalized_positions_tr_spivey_2 <- normalized_positions.new.spivey[ , which(apply(normalized_positions_tr_spivey, 2, var) != 0)]
all_data_columns_spivey2 <- names(dplyr::select(normalized_positions_tr_spivey,
starts_with("x"),
starts_with("y"),
starts_with("v"),
starts_with("a")))
normalized_positions_tr_spivey[all_data_columns_spivey2] <- sapply(normalized_positions_tr_spivey[all_data_columns_spivey2],as.numeric)
final_PCA_DATA <- normalized_positions_tr_spivey %>%
dplyr::select(one_of(all_data_columns))
#Do PCA on the entire data
our_model <- prcomp(final_PCA_DATA, center = TRUE, scale = TRUE)
normalized_positions.new_pca_spivey <- bind_cols(normalized_positions_tr_spivey,
as.data.frame(predict(our_model, final_PCA_DATA)[,1:13]))
lda_measure.new.df_spivey <- data_frame(
lda_measure=c(as.matrix(dplyr::select(normalized_positions.new_pca_spivey, starts_with("PC"))) %*% v_lda- b_lda),
Subject = normalized_positions.new_pca_spivey$Subject,
Item.number = normalized_positions.new_pca_spivey$Item.number,
Polarity = normalized_positions.new_pca_spivey$Polarity,
Response = normalized_positions.new_pca_spivey$Response)
ggplot(lda_measure.new.df_spivey, aes(x = lda_measure, col = Polarity)) + geom_density()
load("/Users/sigurd/Documents/Perception and Action/Perception-Action-Exam/R 2/LDA-Full.RData") #load m_pca etc.
load("/Users/sigurd/Documents/Perception and Action/Perception-Action-Exam/R 2/LDA-Full.RData") #load m_pca etc.
final_PCA_PREDICT <- normalized_positions.new.spivey %>%
dplyr::select(Subject, Item.number, Polarity, Response, one_of(all_data_columns)) %>%
mutate(Subject = as.factor(Subject)) %>%
mutate(Item.number = as.factor(Item.number)) %>%
mutate(Polarity = as.factor(Polarity)) %>%
mutate(Response = as.factor(Response))
#Flip X
X_data_columns_spivey <- names(dplyr::select(final_PCA_PREDICT,
starts_with("x")))
#Flip X
final_PCA_PREDICT[X_data_columns_spivey] <- final_PCA_PREDICT[X_data_columns_spivey]*-1
#Numeric
final_PCA_PREDICT[all_data_columns] <- sapply(final_PCA_PREDICT[all_data_columns],as.numeric)
#CSV FILE FOR
csv_file_for_python = cbind(final_PCA_PREDICT, m$measures)
#write
write_csv(final_PCA_PREDICT, "spivey_data_for_pca.csv")
write_csv(csv_file_for_python, "spivey_data_for_python.csv")
names(csv_file_for_python)
m$measures
#write
write_csv(final_PCA_PREDICT, "spivey_data_for_pca.csv")
#write
write_csv(final_PCA_PREDICT, "spivey_data_for_pca.csv")
write_csv(csv_file_for_python, "spivey_data_for_python.csv")
ggarrange(p1, p2,
ncol = 2, nrow = 1,  align = "hv",
widths = c(0.5, 1), heights = c(1,1), common.legend = FALSE, labels = c("A", "B"))
# Figure 6
p3 <- ggplot(data=subset(auc.bins_change, variable %in% c("Original LDA", "Maximal LogRatio", "X-coordinate flips","Maximal Deviation", "AccFlips", "Topline" , "Baseline", "Area Under Trajectory")), aes(x=bins, y=value, group=variable, colour=variable)) +
geom_line(aes(linetype=point), # Line type depends on cond
size = 1, alpha=.8) +
ylab('Mean AUC') +
xlab('') +
ylim(0.4, 1) +
scale_colour_manual(values=cbPalette) +
theme_minimal() + labs(colour='Classifier') + theme(legend.position = 'right')
p2 <- ggplot(data=subset(auc.bins_change, variable %in% c("Original LDA", "LDA Vel,Acc", "LDA Coords,Vel", "LDA Vel", "LDA Acc", "LDA Coords", "Topline" , "Baseline")), aes(x=bins, y=value, group=variable, colour=variable)) +
p2 <-  ggplot(data=subset(auc.bins_change, variable %in% c("LDA Vel,Acc", "LDA Coords,Vel", "LDA Vel", "LDA Acc", "LDA Coords")), aes(x=bins, y=value, group=variable, colour=variable)) +
geom_line(aes(linetype=point), # Line type depends on cond
size = 1, alpha=.7,  position=position_jitter(w=0, h=0.015)) +
#geom_point(size=2) +
ylab('Mean AUC') +
xlab(' ') +
ylim(0.4, 1) +
scale_colour_manual(values=cbPalette) +
theme_minimal() + labs(colour='Classifier') + theme(legend.position = 'right')
#p2 <- ggplot(data=subset(auc.bins_change, variable %in% c("Original LDA", "LDA Vel,Acc", "LDA Coords,Vel", "LDA Vel", "LDA Acc", "LDA Coords", "Topline" , "Baseline")), aes(x=bins, y=value, group=variable, colour=variable)) +
p2 <-  ggplot(data=subset(auc.bins_change, variable %in% c("LDA Vel,Acc", "LDA Coords,Vel", "LDA Vel", "LDA Acc", "LDA Coords")), aes(x=bins, y=value, group=variable, colour=variable)) +
geom_line(aes(linetype=point), # Line type depends on cond
size = 1, alpha=.7,  position=position_jitter(w=0, h=0.015)) +
#geom_point(size=2) +
ylab('Mean AUC') +
xlab(' ') +
ylim(0.4, 1) +
scale_colour_manual(values=cbPalette) +
theme_minimal() + labs(colour='Classifier') + theme(legend.position = 'right')
#### Cross-validation for other commonly used MT measures
for (b in 1: length(bins)) {
calibrationTrain <- subset(calibration_data, !(id %in% bins[[b]]$id))
calibrationTest <- subset(calibration_data, id %in% bins[[b]]$id)
#AccFlips
accflips.score.te <- calibrationTest$Acc.flips
accflips.label.te <- factor(calibrationTest$Polarity)
accflips.roc.te <- roc(accflips.label.te, accflips.score.te)
auc.bins$accflips[b] <- accflips.roc.te$auc
#MaxLogRatio
maxlogratio.score.te <- calibrationTest$MaxLogRatio
maxlogratio.label.te <- factor(calibrationTest$Polarity)
maxlogratio.roc.te <- roc(maxlogratio.label.te, maxlogratio.score.te)
auc.bins$logratio[b] <- maxlogratio.roc.te$auc
#XFlips
xflips.score.te <- calibrationTest$X.flips
xflips.label.te <- factor(calibrationTest$Polarity)
xflips.roc.te <- roc(xflips.label.te, xflips.score.te)
auc.bins$xflips[b] <- xflips.roc.te$auc
#MaxDeviation
maxdeviation.score.te <- calibrationTest$MaxDeviation
maxdeviation.label.te <- factor(calibrationTest$Polarity)
maxdeviation.roc.te <- roc(maxdeviation.label.te,maxdeviation.score.te)
auc.bins$maxdeviation[b] <- maxdeviation.roc.te$auc
#AUC
auc.score.te <- calibrationTest$AUC
auc.label.te <- factor(calibrationTest$Polarity)
auc.roc.te <- roc(maxdeviation.label.te,auc.score.te)
auc.bins$auc[b] <- auc.roc.te$auc
}
# CLASSIFIER PERFORMANCE ####
#### Bins for cross valiation
calibration_data$id <- 1:nrow(calibration_data)
bins_crossvalidation(calibration_data,'deviated','straight') # Divide the data prepare for CV
#### Data frame to save all the AUCs values for different model features.
auc.bins <- data.frame(bins = c(1:10),
lda.full=c(1:10),
lda.vel.acc=c(1:10),
lda.coord.vel=c(1:10),
lda.vel = c(1:10),
lda.acc=c(1:10),
lda.coord=c(1:10),
logratio=c(1:10),
xflips=c(1:10),
maxdeviation=c(1:10),
accflips=c(1:10),
topline=c(1:10))
# Data frame for iteration of different bins (for baseline)
iterations = 1000
random_classifier.df <- data.frame(matrix(ncol=iterations, nrow=10)) #10 bins 10 rows.
#### Cross-validation for LDA classifier vs. baseline vs. topline
for (b in 1: length(bins)) {
calibrationTrain <- subset(calibration_data, !(id %in% bins[[b]]$id))
calibrationTest <- subset(calibration_data, id %in% bins[[b]]$id)
## FULL LDA
LDA_training.coord.dist(calibrationTrain)
LDA_test.coord.dist(calibrationTest, v_lda, b_lda, m_pca, all_data_columns, n_pca)
#ROC and AUC
lda.score.te <- lda_measure_te.df$lda_measure
lda.label.te <- lda_measure_te.df$Deviation
lda.roc.te <- roc(lda.label.te, lda.score.te)
auc.bins$lda.full[b] <- lda.roc.te$auc
## TOPLINE
calibrationTrain <- subset(calibration_data, !(id %in% bins[[b]]$id))
calibrationTest <- subset(calibration_data, !(id %in% bins[[b]]$id)) #NB: Same data for training and testing
###  TRAINING + TEST
LDA_training.coord.dist(calibrationTrain)
LDA_test.coord.dist(calibrationTest, v_lda, b_lda, m_pca, all_data_columns, n_pca)
lda.score.te <- lda_measure_te.df$lda_measure
lda.label.te <- lda_measure_te.df$Deviation
lda.roc.topline <- roc(lda.label.te, lda.score.te)
lda.topline.auc <- lda.roc.topline$auc
auc.bins$topline[b] <- lda.roc.topline$auc
##BASELINE
calibrationTrain <- subset(calibration_data, !(id %in% bins[[b]]$id))
calibrationTest <- subset(calibration_data, id %in% bins[[b]]$id)
random_classifier(calibrationTrain, calibrationTest, iterations)
###  TRAINING + TEST
for (i in 1:iterations){
point1 <- if_else(i==1, 1, (length(calibrationTest$Polarity)*(i-1))+1)
point2 <- length(calibrationTest$Polarity)*i
#print(c(point1, point2))
random_classifier.iteration <- my[point1:point2]
#score <- calibrationTest$random_classifier#predictor
score <- random_classifier.iteration #predictor
label <- factor(calibrationTest$Polarity) #response
roc <- roc(label, score)
random_classifier.df[b,i] <- roc$auc
}
}
citation(mousetrap)
pacman::p_load(tidyverse, lme4, readbulk)
pacman::p_load(MASS,lme4,GGally,ggpubr, reshape, boot)
pacman::p_load(ellipse, tidyverse, Hmisc, plyr)
pacman::p_load(pROC, devtools, reshape2, mousetrap)
citation("mousetrap")
View(calibration_data_positions)
View(normalized_positions)
as.data.frame(normalized_positions)
as.data.frame(normalized_positions)
all_data_columns_spivey2 <- names(dplyr::select(normalized_positions_tr_spivey,
starts_with("x"),
starts_with("y"),
starts_with("v"),
starts_with("a")))
normalized_positions_tr_spivey[all_data_columns_spivey2] <- sapply(normalized_positions_tr_spivey[all_data_columns_spivey2],as.numeric)
final_PCA_DATA <- normalized_positions_tr_spivey %>%
dplyr::select(one_of(all_data_columns))
#Do PCA on the entire data
our_model <- prcomp(final_PCA_DATA, center = TRUE, scale = TRUE)
normalized_positions.new_pca_spivey <- bind_cols(normalized_positions_tr_spivey,
as.data.frame(predict(our_model, final_PCA_DATA)[,1:13]))
lda_measure.new.df_spivey <- data_frame(
lda_measure=c(as.matrix(dplyr::select(normalized_positions.new_pca_spivey, starts_with("PC"))) %*% v_lda- b_lda),
Subject = normalized_positions.new_pca_spivey$Subject,
Item.number = normalized_positions.new_pca_spivey$Item.number,
Polarity = normalized_positions.new_pca_spivey$Polarity,
Response = normalized_positions.new_pca_spivey$Response)
ggplot(lda_measure.new.df_spivey, aes(x = lda_measure, col = Polarity)) + geom_density()
normalized_positions.new_pca_spivey <- bind_cols(normalized_positions_tr_spivey,
as.data.frame(predict(our_model, final_PCA_DATA)[,1:13]))
lda_measure.new.df_spivey <- data_frame(
lda_measure=c(as.matrix(dplyr::select(normalized_positions.new_pca_spivey, starts_with("PC"))) %*% v_lda- b_lda),
Subject = normalized_positions.new_pca_spivey$Subject,
Item.number = normalized_positions.new_pca_spivey$Item.number,
Polarity = normalized_positions.new_pca_spivey$Polarity,
Response = normalized_positions.new_pca_spivey$Response)
ggplot(lda_measure.new.df_spivey, aes(x = lda_measure, col = Polarity)) + geom_density()
#TIME TO PREDICT
predict(m_pca, final_PCA_PREDICT)
# Test names
colnames(final_PCA_PREDICT) == colnames(normalized_positions.new)
ncol(final_PCA_PREDICT) == ncol(normalized_positions.new)
as.data.frame(final_PCA_PREDICT)
as.data.frame(normalized_positions.new)
#TIME TO PREDICT
predict(m_pca, final_PCA_PREDICT)
# Test names to see if they match.
colnames(final_PCA_PREDICT) == colnames(normalized_positions.new)
ncol(final_PCA_PREDICT) == ncol(normalized_positions.new)
#TIME TO PREDICT
#predict(m_pca, final_PCA_PREDICT)
# Test names to see if they match.
#colnames(final_PCA_PREDICT) == colnames(normalized_positions.new)
#ncol(final_PCA_PREDICT) == ncol(normalized_positions.new)
LDA_training.coord.dist(calibration_data)
LDA_training.coord.dist(calibration_data)
#Used in Python
write_csv(pca_data_python, "PCA_CALIBRATION_2.csv")
### GO INTO norm_positions_LDA.R and run to get normalized_positions.
normalized_positions.new <- normalized_positions %>%
dplyr::select(Subject, Item.number, Polarity, Response, one_of(all_data_columns))
write.csv(normalized_positions.new, "Sigurd_Negation_PCA_data.csv")
### GO INTO norm_positions_LDA.R and run to get normalized_positions.
normalized_positions.new <- normalized_positions %>%
dplyr::select(Subject, Item.number, Polarity, Response, one_of(all_data_columns))
write.csv(normalized_positions.new, "Sigurd_Negation_PCA_data.csv")
##CLASSIFIER PERFORMANCE ####
### Full LDA
load('/Users/sigurd/OneDrive - Aarhus Universitet/Perception and Action (3rd Semester)/Perception And Action EXAM/R 2/LDA-Full.RData')
### GO INTO norm_positions_LDA.R and run to get normalized_positions.
normalized_positions.new <- normalized_positions %>%
dplyr::select(Subject, Item.number, Polarity, Response, one_of(all_data_columns))
## Load Data
negation_info <- read.csv(file="/Users/sigurd/OneDrive - Aarhus Universitet/Perception and Action (3rd Semester)/Perception And Action EXAM/data_R/negation_info.csv", header=TRUE, sep=",")
negation_data <- read.csv(file="/Users/sigurd/OneDrive - Aarhus Universitet/Perception and Action (3rd Semester)/Perception And Action EXAM/data_R/negation_data_simple.csv", header=TRUE, sep=",")
negation_data_positions <- read.csv(file="/Users/sigurd/OneDrive - Aarhus Universitet/Perception and Action (3rd Semester)/Perception And Action EXAM/data_R/negation_data_positions.csv", header=TRUE, sep=",")
x <- paste0('x', sprintf("%03d", c(1:101)))
y <- paste0('y', sprintf("%03d", c(1:101)))
## SUBJECT and TRIAL EXCLUSION ####
###  Excluding not natives English speakers
natives <- subset(negation_info, grepl('en',negation_info$Language, ignore.case=TRUE))
not_natives <- subset(negation_info, !(Subject %in% natives$Subject))
negation_info<- subset(negation_info, !(Subject %in% not_natives$Subject))
negation_data <- subset(negation_data, !(Subject %in% not_natives$Subject))
negation_data_positions <- subset(negation_data_positions, !(Subject %in% not_natives$Subject))
rm(natives, not_natives)
### Excluding unaccurate trials
non_accurate_data <- subset (negation_data, Accuracy==FALSE)
print('percentage of innaccurate trials:')
print(nrow(non_accurate_data)/nrow(negation_data))
negation_data <- subset(negation_data, Accuracy==TRUE)
negation_data_positions <- subset(negation_data_positions, Accuracy==TRUE)
## OVERALL PERFORMANCE ####
### Negation_data_posistion
normalized_positions.means.subject <- ddply(negation_data_positions, c("Polarity", "Time.Step", "Expected_response", "Subject"),                                                   function(negation_data_positions)c(X.Position.mean=mean(negation_data_positions$X.Position, na.rm=T),
Y.Position.mean=mean(negation_data_positions$Y.Position, na.rm=T)))
### Norm posistion
normalized_positions.means.traj <- ddply(normalized_positions.means.subject, c("Polarity", "Time.Step", "Expected_response"),
function(normalized_positions.means.subject)c(X.Position.mean=mean(normalized_positions.means.subject$X.Position.mean, na.rm=T),
X.Position.se=se(normalized_positions.means.subject$X.Position.mean, na.rm=T),
Y.Position.mean=mean(normalized_positions.means.subject$Y.Position.mean, na.rm=T),
Y.Position.se=se(normalized_positions.means.subject$Y.Position.mean, na.rm=T)))
## plot
ggplot(normalized_positions.means.traj, aes(x=X.Position.mean, y=Y.Position.mean, color=Polarity, group=Polarity)) +
geom_point(alpha=.5) +
ggtitle('') +
xlab('X Coordinate') +
ylab('Y Coordinate') +
geom_errorbarh(aes(xmin=X.Position.mean-X.Position.se, xmax=X.Position.mean+X.Position.se), alpha=.4) +
theme_minimal()+
expand_limits(x=c(-1.5,1.5)) +
scale_colour_manual(values=c("#DB172A", "#1470A5"),
name="Polarity",
breaks=c("N", "P"),
labels=c("Negative", "Positive"))+
facet_grid(.~Expected_response)
mydata <- negation_data
mydata$Expected_response <- factor(mydata$Expected_response)
mydata$Polarity <- factor(mydata$Polarity)
contrasts(mydata$Expected_response) <- c(-0.5, 0.5)
contrasts(mydata$Polarity) <- c(0.5, -0.5)
mydata$Interaction<-factor(contrasts(mydata$Polarity)[mydata$Polarity]*
contrasts(mydata$Expected_response)[mydata$Expected_response])
### Mean values
xflips.means.subj <- ddply(mydata, c("Polarity", "Expected_response", "Subject"),
function(mydata)c(mean=mean(mydata$X.flips, na.rm=T)))
xflips.means <- ddply(xflips.means.subj, c("Polarity", "Expected_response"),
function(xflips.means.subj)c(mean=mean(xflips.means.subj$mean, na.rm=T), se = se(xflips.means.subj$mean)))
### Main effects
control_model1.lda <- lmer(X.flips ~ Polarity + Expected_response + Interaction + (1+Polarity*Expected_response|Subject), data = mydata, REML=FALSE)
#Main Effect: Polarity (Affirmative vs. Negative)
m0.sentence.lda <- lmer(X.flips ~ Expected_response  +Interaction + (1+Polarity*Expected_response|Subject), data = mydata, REML=FALSE) #the value of intercept is not exactly the same as the one in my aggregate function, why?
anova(control_model1.lda, m0.sentence.lda)
#Main Effect :Expected_response (True vs. False)
m0.response.lda <- lmer(X.flips ~ Polarity  + Interaction+ (1+Polarity*Expected_response|Subject), data = mydata, REML=FALSE) #the value of intercept is not exactly the same as the one in my aggregate function, why?
anova(control_model1.lda, m0.response.lda)
### Effect of Interaction
control_model2.lda <- lmer(X.flips ~ Polarity*Expected_response + (1+Polarity*Expected_response|Subject), data = mydata, REML=FALSE)
m0.interaction.lda <- lmer(X.flips~ Polarity+Expected_response+ (1+Polarity*Expected_response|Subject), data = mydata, REML=FALSE) #the value of intercept is not exactly the same as the one in my aggregate function, why?
anova(control_model2.lda, m0.interaction.lda)
##CLASSIFIER PERFORMANCE ####
### Full LDA
load('/Users/sigurd/OneDrive - Aarhus Universitet/Perception and Action (3rd Semester)/Perception And Action EXAM/R 2/LDA-Full.RData')
### GO INTO norm_positions_LDA.R and run to get normalized_positions.
normalized_positions.new <- normalized_positions %>%
dplyr::select(Subject, Item.number, Polarity, Response, one_of(all_data_columns))
### Testing LDA on negation data
#Create data frame for LDA
x <- paste0('x', sprintf("%03d", c(1:101)))
y <- paste0('y', sprintf("%03d", c(1:101)))
a <- paste0('a', sprintf("%03d", c(1:101)))
v <- paste0('v', sprintf("%03d", c(1:101)))
t <- paste0('t', sprintf("%03d", c(1:101)))
# Each x and y coordenate into two columns (101 coordenates per trial)
normalized_positions = negation_data %>%
dplyr::select(Subject, Item.number, Polarity, Response, Normalized.positions.X,Normalized.positions.Y, Velocity, Acceleration, RawTime) %>%
separate(Normalized.positions.Y, into= y, sep = ",") %>%
separate(Normalized.positions.X, into= x, sep = ",") %>%
separate(Velocity, into= v, sep = ",") %>%
separate(RawTime, into= t, sep = ",") %>%
separate(Acceleration, into= a, sep = ",")
normalized_positions[y] <- sapply(normalized_positions[y],as.numeric)
normalized_positions[x] <- sapply(normalized_positions[x],as.numeric)
normalized_positions[v] <- sapply(normalized_positions[v],as.numeric)
normalized_positions[a] <- sapply(normalized_positions[a],as.numeric)
normalized_positions[t] <- sapply(normalized_positions[t],as.numeric)
# Taking the negative of false items, to have everything in the same scale
normalized_positions_false = normalized_positions%>%
filter(Response=='false')%>%
dplyr::mutate_at(vars(starts_with('x')), funs('-'))
normalized_positions_true = filter(normalized_positions, Response=='true')
normalized_positions = bind_rows(normalized_positions_false,normalized_positions_true)
rm(normalized_positions_true, normalized_positions_false)
#More about classes
normalized_positions$Subject <- factor(normalized_positions$Subject)
normalized_positions$Polarity <- factor(normalized_positions$Polarity)
normalized_positions$Response <- factor(normalized_positions$Response)
### GO INTO norm_positions_LDA.R and run to get normalized_positions.
normalized_positions.new <- normalized_positions %>%
dplyr::select(Subject, Item.number, Polarity, Response, one_of(all_data_columns))
write.csv(normalized_positions.new, "Sigurd_Negation_PCA_data.csv")
#write
write_csv(final_PCA_PREDICT, "spivey_data_for_pca.csv")
#FILE USED in Python script.
write_csv(csv_file_for_python, "spivey_data_for_python.csv")
#write
write_csv(final_PCA_PREDICT, "spivey_data_for_pca.csv")
#FILE USED in Python script.
write_csv(csv_file_for_python, "spivey_data_for_python.csv")
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(AER)
pacman::p_load(AER)
dispersiontest(m1)
risky_df <- read_dta("C:/Users/sigur/Desktop/github_methods_3/Gelman-Hill_Exercises/Data/risky_behaviors.dta")
pacman::p_load(tidyverse,haven)
risky_df <- read_dta("C:/Users/sigur/Desktop/github_methods_3/Gelman-Hill_Exercises/Data/risky_behaviors.dta")
pacman::p_load(tidyverse,haven)
risky_df <- read_dta("C:/Users/sigur/Desktop/github_methods_3/Gelman-Hill_Exercises/Data/risky_behaviors.dta")
risky_df <- read_dta("C:/Users/sigur/Desktop/github_methods_3/Gelman-Hill_Exercises/Data/risky_behaviors.dta")
#Select only those with X,Y,V,A
all_data_columns_spivey <- names(dplyr::select(spivey_df_data,
starts_with("x"),
starts_with("y"),
starts_with("v"),
starts_with("a")))
normalized_positions.new.spivey <- spivey_df_data %>%
dplyr::select(Subject, Item.number, Polarity, Response, one_of(all_data_columns_spivey))
#Find Constant Col's
constant_columns_ctl <- normalized_positions.new.spivey %>%
filter(Polarity == "control") %>%
dplyr::select(starts_with("x"), starts_with("y"), starts_with('v'), starts_with('a')) %>%
find_constant
find_constant <- function(d, epsilon=1e-4) {
names(d)[apply(d,2,function(x) is.na(var(x)) || sqrt(var(x)) < epsilon)]
}
#Experiment but didn't work.
load("/Users/sigurd/Documents/Perception and Action/Perception-Action-Exam/R 2/LDA-Full.RData") #load m_pca etc.
#Experiment but didn't work.
load("/Users/sigurd/Documents/Perception and Action/Perception-Action-Exam/R 2/LDA-Full.RData") #load m_pca etc.
#Experiment but didn't work.
load("/Users/sigurd/Documents/Perception and Action/Perception-Action-Exam/R 2/LDA-Full2.RData") #load m_pca etc.
